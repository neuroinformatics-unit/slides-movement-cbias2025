@misc{blackcap_preprint,
	title = {Mapping the magnetoreceptive brain: {A} {3D} digital atlas of the migratory bird {Eurasian} blackcap ( \textit{{Sylvia} atricapilla} )},
	copyright = {http://creativecommons.org/licenses/by/4.0/},
	shorttitle = {Mapping the magnetoreceptive brain},
	url = {http://biorxiv.org/lookup/doi/10.1101/2025.03.04.641293},
	doi = {10.1101/2025.03.04.641293},
	abstract = {Birds undisputedly range amongst nature's foremost navigators. To successfully navigate between breeding and wintering quarters, they, in addition to other natural orientation cues, rely on their ability to sense the Earth's magnetic field. For this reason, migratory birds have become key model species for studying the sensory mechanisms underlying magnetic field-guided navigation, as evidenced by the identification of several brain regions believed to be involved in processing magnetic field information. However, there is as yet no readily accessible, high-resolution three-dimensional (3D) brain atlas to serve as a common reference within and across studies. Here we provide the neuroscience research community with the first freely available, digital, high-resolution (25 µm), 3D bird brain atlas. It is based on light microscopy images from ten Eurasian blackcaps (Sylvia atricapilla), a night-migratory songbird widely used model species in magnetoreception and navigation research. We outline the individual steps for the creation of a brain atlas, from whole-brain imaging using serial-section, two-photon tomography, to the creation of an average template at an isotropic 25- µm voxel size, and finally to brain area segmentation and annotation. In this first version of the atlas, we have mapped a total of 24 brain areas, including 6 principal compartments, 13 conspicuous anatomical subdivisions common to all bird species and 5 functionally defined areas of the visual and trigeminal sensory systems involved in processing magnetic field information. This atlas is accessible via the standardised BrainGlobe Atlas API, making it compatible with a growing suite of computational neuroanatomy tools provided by the BrainGlobe Initiative. This integration enables precise alignment of future experimental data to a common coordinate space, facilitating collaboration, data visualization and sharing. Furthermore, this resource enables the accurate localization and comparison of implanted devices, injection sites, and/or cell populations across individual brains, both within and across studies.},
	language = {en},
	urldate = {2025-03-17},
	author = {Sirmpilatze, Nikoloz and Felder, Alessandro and Abdulazhanova, Dinora and Schwigon, Leonard and Haase, Katrin and Musielak, Isabelle and Margrie, Troy W. and Mouritsen, Henrik and Heyers, Dominik and Tyson, Adam L. and Weiler, Simon},
	month = mar,
	year = {2025},
	file = {Sirmpilatze et al. - 2025 - Mapping the magnetoreceptive brain A 3D digital a.pdf:/Users/nsirmpilatze/Zotero/storage/LFDQ4NBG/Sirmpilatze et al. - 2025 - Mapping the magnetoreceptive brain A 3D digital a.pdf:application/pdf},
}

@book{tinbergen_study_1951,
	title = {The {Study} of {Instinct}},
	isbn = {978-0-19-857343-2},
	language = {en},
	publisher = {Clarendon Press},
	author = {Tinbergen, Niko},
	year = {1951},
	note = {Google-Books-ID: ZtUlAAAAMAAJ},
}

@article{levitis_behavioural_2009,
	title = {Behavioural biologists don't agree on what constitutes behaviour},
	volume = {78},
	issn = {0003-3472},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2760923/},
	doi = {10.1016/j.anbehav.2009.03.018},
	abstract = {Behavioural biology is a major discipline within biology, centred on the key concept of `behaviour.' But how is `behaviour' defined, and how should it be defined? We outline what characteristics we believe a scientific definition should have, and why we think it important that a definition have these traits. We then examine the range of available published definitions for the word. Finding no consensus, we present survey responses from 174 members of three behaviour-focused scientific societies as to their understanding of the term. Here again, we find surprisingly widespread disagreement as to what qualifies as behaviour. Respondents contradict themselves, each other, and published definitions, indicating that they are using individually variable intuitive, rather than codified, meanings of `behaviour.' We offer a new definition, based largely on survey responses: “Behaviour is the internally coordinated responses (actions or inactions) of whole living organisms (individuals or groups) to internal and/or external stimuli, excluding responses more easily understood as developmental changes.” Finally, we discuss the usage, meanings and limitations of this definition.},
	number = {1},
	urldate = {2022-11-21},
	journal = {Animal behaviour},
	author = {Levitis, Daniel A. and Lidicker, William Z. and Freund, Glenn},
	month = jul,
	year = {2009},
	pmid = {20160973},
	pmcid = {PMC2760923},
	pages = {103--110},
	file = {PubMed Central Full Text PDF:/Users/nsirmpilatze/Zotero/storage/HCJ8HI4V/Levitis et al. - 2009 - Behavioural biologists don't agree on what constit.pdf:application/pdf},
}

@article{ants_crispr_2017,
	title = {{CRISPR} ants lose ability to smell},
	volume = {548},
	copyright = {2017 Springer Nature Limited},
	url = {https://www.nature.com/articles/d41586-017-02337-4},
	doi = {10.1038/d41586-017-02337-4},
	abstract = {First gene-edited mutant-ant lines show defects in social behaviour.},
	language = {en},
	number = {7667},
	urldate = {2025-08-10},
	journal = {Nature},
	month = aug,
	year = {2017},
	note = {Bandiera\_abtest: a
Cg\_type: Research Highlight
Publisher: Nature Publishing Group
Subject\_term: Genetics},
	keywords = {Genetics},
	pages = {263--263},
	file = {Snapshot:/Users/nsirmpilatze/Zotero/storage/PTXHAIUY/d41586-017-02337-4.html:text/html},
}

@article{mathis_primer_2020,
	title = {A {Primer} on {Motion} {Capture} with {Deep} {Learning}: {Principles}, {Pitfalls}, and {Perspectives}},
	volume = {108},
	issn = {0896-6273},
	shorttitle = {A {Primer} on {Motion} {Capture} with {Deep} {Learning}},
	url = {https://www.sciencedirect.com/science/article/pii/S0896627320307170},
	doi = {10.1016/j.neuron.2020.09.017},
	abstract = {Extracting behavioral measurements non-invasively from video is stymied by the fact that it is a hard computational problem. Recent advances in deep learning have tremendously advanced our ability to predict posture directly from videos, which has quickly impacted neuroscience and biology more broadly. In this primer, we review the budding field of motion capture with deep learning. In particular, we will discuss the principles of those novel algorithms, highlight their potential as well as pitfalls for experimentalists, and provide a glimpse into the future.},
	language = {en},
	number = {1},
	urldate = {2022-11-24},
	journal = {Neuron},
	author = {Mathis, Alexander and Schneider, Steffen and Lauer, Jessy and Mathis, Mackenzie Weygandt},
	month = oct,
	year = {2020},
	pages = {44--65},
	file = {ScienceDirect Full Text PDF:/Users/nsirmpilatze/Zotero/storage/FCQKPT37/Mathis et al. - 2020 - A Primer on Motion Capture with Deep Learning Pri.pdf:application/pdf;ScienceDirect Snapshot:/Users/nsirmpilatze/Zotero/storage/K8WDCKX4/S0896627320307170.html:text/html},
}

@article{mathis_deeplabcut_2018,
	title = {{DeepLabCut}: markerless pose estimation of user-defined body parts with deep learning},
	volume = {21},
	copyright = {2018 The Author(s)},
	issn = {1546-1726},
	shorttitle = {{DeepLabCut}},
	url = {https://www.nature.com/articles/s41593-018-0209-y},
	doi = {10.1038/s41593-018-0209-y},
	abstract = {Quantifying behavior is crucial for many applications in neuroscience. Videography provides easy methods for the observation and recording of animal behavior in diverse settings, yet extracting particular aspects of a behavior for further analysis can be highly time consuming. In motor control studies, humans or other animals are often marked with reflective markers to assist with computer-based tracking, but markers are intrusive, and the number and location of the markers must be determined a priori. Here we present an efficient method for markerless pose estimation based on transfer learning with deep neural networks that achieves excellent results with minimal training data. We demonstrate the versatility of this framework by tracking various body parts in multiple species across a broad collection of behaviors. Remarkably, even when only a small number of frames are labeled ({\textasciitilde}200), the algorithm achieves excellent tracking performance on test frames that is comparable to human accuracy.},
	language = {en},
	number = {9},
	urldate = {2022-11-08},
	journal = {Nature Neuroscience},
	author = {Mathis, Alexander and Mamidanna, Pranav and Cury, Kevin M. and Abe, Taiga and Murthy, Venkatesh N. and Mathis, Mackenzie Weygandt and Bethge, Matthias},
	month = sep,
	year = {2018},
	note = {Number: 9
Publisher: Nature Publishing Group},
	keywords = {Computational neuroscience, Bs41592-022-01426-1ehavioural methods, Machine learning},
	pages = {1281--1289},
	file = {Mathis et al. - 2018 - DeepLabCut markerless pose estimation of user-def.pdf:/Users/nsirmpilatze/Zotero/storage/I2K9ZHDW/Mathis et al. - 2018 - DeepLabCut markerless pose estimation of user-def.pdf:application/pdf;Snapshot:/Users/nsirmpilatze/Zotero/storage/WDSLJFIR/s41593-018-0209-y.html:text/html},
}

@article{pereira_sleap_2022,
	title = {{SLEAP}: {A} deep learning system for multi-animal pose tracking},
	volume = {19},
	copyright = {2022 The Author(s)},
	issn = {1548-7105},
	shorttitle = {{SLEAP}},
	url = {https://www.nature.com/articles/s41592-022-01426-1},
	doi = {10.1038/s41592-022-01426-1},
	abstract = {The desire to understand how the brain generates and patterns behavior has driven rapid methodological innovation in tools to quantify natural animal behavior. While advances in deep learning and computer vision have enabled markerless pose estimation in individual animals, extending these to multiple animals presents unique challenges for studies of social behaviors or animals in their natural environments. Here we present Social LEAP Estimates Animal Poses (SLEAP), a machine learning system for multi-animal pose tracking. This system enables versatile workflows for data labeling, model training and inference on previously unseen data. SLEAP features an accessible graphical user interface, a standardized data model, a reproducible configuration system, over 30 model architectures, two approaches to part grouping and two approaches to identity tracking. We applied SLEAP to seven datasets across flies, bees, mice and gerbils to systematically evaluate each approach and architecture, and we compare it with other existing approaches. SLEAP achieves greater accuracy and speeds of more than 800 frames per second, with latencies of less than 3.5 ms at full 1,024 × 1,024 image resolution. This makes SLEAP usable for real-time applications, which we demonstrate by controlling the behavior of one animal on the basis of the tracking and detection of social interactions with another animal.},
	language = {en},
	number = {4},
	urldate = {2022-11-08},
	journal = {Nature Methods},
	author = {Pereira, Talmo D. and Tabris, Nathaniel and Matsliah, Arie and Turner, David M. and Li, Junyu and Ravindranath, Shruthi and Papadoyannis, Eleni S. and Normand, Edna and Deutsch, David S. and Wang, Z. Yan and McKenzie-Smith, Grace C. and Mitelut, Catalin C. and Castro, Marielisa Diez and D’Uva, John and Kislin, Mikhail and Sanes, Dan H. and Kocher, Sarah D. and Wang, Samuel S.-H. and Falkner, Annegret L. and Shaevitz, Joshua W. and Murthy, Mala},
	month = apr,
	year = {2022},
	note = {Number: 4
Publisher: Nature Publishing Group},
	keywords = {Computational neuroscience, Software, Machine learning},
	pages = {486--495},
	file = {Full Text PDF:/Users/nsirmpilatze/Zotero/storage/KZWJJE4T/Pereira et al. - 2022 - SLEAP A deep learning system for multi-animal pos.pdf:application/pdf;Snapshot:/Users/nsirmpilatze/Zotero/storage/Y662EYII/s41592-022-01426-1.html:text/html},
}